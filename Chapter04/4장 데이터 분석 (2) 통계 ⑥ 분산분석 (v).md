## 4장 데이터 분석 (2) 통계 ⑥ 분산분석 (v)

​

​

#### 5) 이원분산분석/다원분산분석

​     

이원분산분석은 이(二) 원(元)이므로 원인(근본)이 되는 변수가 2개라는 뜻입니다. 분산분석에서는 원인에 해당하는 변수가 독립변수이므로 **독립변수가 2개인 경우 사용하는 분산분석**이라는 뜻입니다. 

​     

이원분산분석의 필요성은 '집단 간 평균 차이를 일원분산분석(독립변수 1개)으로 분석했지만, 제3의 변수가 영향을 주어 나타났을 것이다'에서 시작합니다. 때문에 제3의 변수를 독립변수에 넣고, 제3의 변수(조절변수)로 인해 평균 차이가 나타나거나 사라지는지 확인하는 방법입니다.

참고로 독립변수가 2개 이상 들어가는 분산분석을 **팩토리얼 디자인**이라고도 부릅니다.

​

이원분산분석에서는 독립변수 간 항목 개수를 서로 곱해서 분산분석을 실시하기 때문에 집단의 개수가 a * b개가 됩니다. 독립변수가 3개 이상일 때의 분산분석인 다원분산분석의 경우, 집단의 개수는 a * b * c개가 됩니다.

​

이원분산분석에서도 주효과(독립변수→종속변수에 미치는 영향)를 분석하지만, 2차 주효과(독립변수 간 상호작용)도 분석해야 하며 오히려 **상호작용효과가 주요 분석 대상**입니다.

​     

**① 상호작용/교호작용 효과**

독립변수가 서로 영향을 주는 것을 상호작용 효과라고 합니다. 특히 임상 실험에서 투약을 제외하고 실험 집단과 통제 집단 사이에 어떤 요인으로 인해 값이 달라지는 현상을 말합니다. 예를 들어 성별, 연령, 심리적 요인 등이 있습니다.

때문에 상호작용 효과를 검정한다는 것은 독립변수들의 항목을 곱한 서브 집단을 만들어 어떤 집단이 가장 종속변수에 미치는 영향이 큰지 확인합니다.

2차 효과(조절 변수)를 검증했는데 1차 효과가 달라지지 않으면 시/공간을 초월해 1차 효과가 나타난다고 해석합니다. 분산분석에서 독립변수는 범주형 변수에 해당하므로 조절변수(독립변수)를 얼마나 많이 넣는가에 따라 차원이 올라가고, 서브 집단의 개수도 늘어나 해석이 어려워집니다.

마지막으로 p-value를 보지 않고 그래프를 통해 상호작용효과를 확인할 수 있습니다. 독립변수별로 평균을 꺾은선 그래프로 연결할 때 선이 교차하면 상호작용효과가 있다고 해석합니다.

참고로 수치형(연속변수) 조절변수는 종속변수에 해당하므로 수치형 조절변수를 넣으면 공변량 분석이라고 부릅니다. 자세한 내용은 공변량 분석에서 확인하겠습니다.

​     

**② 절차**

​     

기본적인 절차는 일원분산분석과 같습니다. 가설을 설정하고 분산분석 검정(함수)를 사용해 가설을 검증합니다. 또한, 어떤 집단이 가장 평균 차이가 나는지 사후 검증을 통해 확인합니다.

​     

i) 가설 설정

​     

가) 상호 효과 : 요인 간에 교차된 효과가 나타나는가?(요인 간 상호작용 효과가 나타나는가?)

​     

귀무가설 : 독립변수 간 상호작용 효과가 없다.(제3의 변수와 상관없이 독립변수와 종속변수 사이에 효과가 나타난 것이다.)

대립가설 : 독립변수 간 상호작용 효과가 있다.(제3의 변수에 의해 독립변수와 종속변수 사이에 효과가 나타난 것이다.)

​     

나) 주 효과 : 요인(집단) 간 평균 차이가 나는가?

​     

귀무가설 : 모든 집단의 평균이 같다  

대립가설 : 적어도 한 집단의 평균은 나머지 집단의 평균과 다르다 

​     

ii) 분산분석 시행(aov, anova 함수)

​     

다원분산분석에서는 독립성 검정이나 등분산성 검정을 실시하지 않습니다.

바로 분산분석을 시행하면 되는데, 일원분산분석처럼 아무렇게나 독립변수를 넣는 것이 아니라 순서가 있습니다.

​     

aov 함수에 관계식(formula)을 넣는 경우, **종속변수 ~ 독립변수 + 2차 주효과 변수** 순서로 넣어야 합니다.

또는 종속변수 ~ 1차 독립변수 + 2차 독립변수(처치변수) + 1차 독립변수:2차 독립변수(상호작용효과)의 순서입니다.

​     

이후 summary( ) 함수를 통해 결과를 확인하면, 독립변수와 상호작용변수의 유의성을 확인할 수 있습니다. 상호작용변수도 관찰 F통계량을 구할 수 있지만, 여기서는 p-value를 통해 간단히 결과를 확인하는 것으로 마치겠습니다. 이원분산분석의 F통계량과 관련된 자료를 보고 싶으시면 아래 사이트로 가시기 바랍니다.

​     

https://swmh.tistory.com/136

​     

iii) 가설 검정

​     

우선 상호작용변수의 p-value가 0.05 이하면, 독립변수 간 상호작용효과가 있다고 해석합니다. 즉, 1차 독립변수로 구분한 집단별로 종속변수의 차이가 있다고 해도 중요하지 않다는 뜻입니다. 반대로 상호작용변수의 p-value가 0.05 이상이면 독립변수 간 상호작용효과가 없으며, 1차 독립변수에 따른 집단별 종속변수의 차이는 유의미합니다.

​     

iv) 사후검정(TukeyHSD, multcomp::glht 함수 이용)

​     

사후검정도 일원분산분석과 비슷합니다. 독립변수들의 항목끼리 곱한 서브 집단별로 얼마나 평균 차이가 유의미한지 p-value로 나타내는데, 이것이 0.05 이하면 그 집단의 평균이 다른 집단보다 크게 다르다는 뜻입니다.

사후검정은 특히 상호작용효과가 있을 때 중요한데, 어떤 서브 집단이 가장 평균이 다른지 알 수 있어 대안을 마련하기 쉽기 때문입니다. 그러나 주의할 점은 독립변수의 항목이 너무 많으면 기계적으로 모든 항목을 곱해버리므로 해석이 어려울 수 있습니다.

​     

glht 함수에 비해 TukeyHSD 함수가 가지는 장점은 TukeyHSD는 diff(두 집단의 평균 차이), lwr/upr(95% 신뢰구간에서의 상/하한값), p adj = p-value(얼마나 평균 차이가 유의한가?)를 보여주므로 glht보다 직관적입니다. glht도 p-value는 보여주지만 t-통계량, 표준오차를 보여주므로 다소 해석이 어렵습니다.

​

​     

#### 참고문헌

​     

C강사님의 강의노트

L교수님의 통계수업

​     

이종익, 박민석 편저, 「사회조사분석사 2급 필기」, 시대고시기획, 2014.

최용석, 「R과 함께하는 통계학의 이해」, BigBook, 2014.

​

--2018.10.23

